type: com.google.api.codegen.ConfigProto
config_schema_version: 1.0.0
language_settings:
  java:
    package_name: com.google.cloud.speech.v1p1beta1
  python:
    package_name: google.cloud.speech_v1p1beta1.gapic
  go:
    package_name: cloud.google.com/go/speech/apiv1p1beta1
  csharp:
    package_name: Google.Cloud.Speech.V1P1Beta1
  ruby:
    package_name: Google::Cloud::Speech::V1p1beta1
  php:
    package_name: Google\Cloud\Speech\V1p1beta1
  nodejs:
    package_name: speech.v1p1beta1
    domain_layer_location: google-cloud
interfaces:
- name: google.cloud.speech.v1p1beta1.Speech
  smoke_test:
    method: Recognize
    init_fields:
    - config.language_code="en-US"
    - config.sample_rate_hertz=44100
    - config.encoding=FLAC
    - audio.uri="gs://gapic-toolkit/hello.flac"
  collections: []
  retry_codes_def:
  - name: idempotent
    retry_codes:
    - DEADLINE_EXCEEDED
    - UNAVAILABLE
  - name: non_idempotent
    retry_codes: []
  retry_params_def:
  - name: default
    initial_retry_delay_millis: 100
    retry_delay_multiplier: 1.3
    max_retry_delay_millis: 60000
    initial_rpc_timeout_millis: 1000000
    rpc_timeout_multiplier: 1
    max_rpc_timeout_millis: 1000000
    total_timeout_millis: 5000000
  methods:
  - name: Recognize
    flattening:
      groups:
      - parameters:
        - config
        - audio
    required_fields:
    - config
    - audio
    sample_code_init_fields:
    - config.encoding=FLAC
    - config.sample_rate_hertz=44100
    - config.language_code="en-US"
    - audio.uri=gs://bucket_name/file_name.flac
    retry_codes_name: idempotent
    retry_params_name: default
    timeout_millis: 1000000
    samples:
      standalone:
      - region_tag: speech_transcribe_word_level_confidence_beta
        value_sets:
        - speech_transcribe_word_level_confidence_beta
      - region_tag: speech_transcribe_multilanguage_beta
        value_sets:
        - speech_transcribe_multilanguage_beta
      - region_tag: speech_transcribe_recognition_metadata_beta
        value_sets:
        - speech_transcribe_recognition_metadata_beta
      - region_tag: speech_transcribe_auto_punctuation_beta
        value_sets:
        - speech_transcribe_auto_punctuation_beta
      - region_tag: speech_quickstart_beta
        value_sets:
        - speech_quickstart_beta
      - region_tag: speech_adaptation_beta
        value_sets:
        - speech_adaptation_beta
      - region_tag: speech_contexts_classes_beta
        value_sets:
        - speech_contexts_classes_beta
    sample_value_sets:
    - id: speech_transcribe_word_level_confidence_beta
      title: Enabling word-level confidence (Local File) (Beta)
      description: 'Print confidence level for individual words in a transcription
        of a short audio file

'
      parameters:
        defaults:
        - audio.content = "resources/brooklyn_bridge.flac"
        - config.enable_word_confidence = True
        - config.language_code = "en-US"
        attributes:
        - parameter: audio.content
          sample_argument_name: local_file_path
          read_file: true
          description: Path to local audio file, e.g. /path/audio.wav
        - parameter: config.enable_word_confidence
          description: |
            When enabled, the first result returned by the API will include a list
            of words and the confidence level for each of those words.
        - parameter: config.language_code
          description: The language of the supplied audio
      on_success:
      - comment:
        - The first result includes confidence levels per word
      - define: result=$resp.results[0]
      - comment:
        - First alternative is the most probable result
      - define: alternative=result.alternatives[0]
      - print:
        - 'Transcript: %s'
        - alternative.transcript
      - comment:
        - Print the confidence level of each word
      - loop:
          collection: alternative.words
          variable: word
          body:
          - print:
            - 'Word: %s'
            - word.word
          - print:
            - 'Confidence: %s'
            - word.confidence
    - id: speech_transcribe_multilanguage_beta
      title: Detecting language spoken automatically (Local File) (Beta)
      description: 'Transcribe a short audio file with language detected from a list
        of possible languages

'
      parameters:
        defaults:
        - audio.content = "resources/brooklyn_bridge.flac"
        - config.language_code = "fr"
        - config.alternative_language_codes[0] = "es"
        - config.alternative_language_codes[1] = "en"
        attributes:
        - parameter: audio.content
          sample_argument_name: local_file_path
          read_file: true
          description: Path to local audio file, e.g. /path/audio.wav
        - parameter: config.alternative_language_codes[0]
          description: 'Specify up to 3 additional languages as possible alternative
            languages of the supplied audio.

'
        - parameter: config.language_code
          description: |
            The language of the supplied audio. Even though additional languages are
            provided by alternative_language_codes, a primary language is still required.
      on_success:
      - loop:
          variable: result
          collection: "$resp.results"
          body:
          - comment:
            - The %s which was detected as the most likely being spoken in the audio
            - language_code
          - print:
            - 'Detected language: %s'
            - result.language_code
          - comment:
            - First alternative is the most probable result
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
    - id: speech_transcribe_auto_punctuation_beta
      title: Getting punctuation in results (Local File) (Beta)
      description: 'Transcribe a short audio file with punctuation

'
      parameters:
        defaults:
        - audio.content = "resources/commercial_mono.wav"
        - config.enable_automatic_punctuation = True
        - config.language_code = "en-US"
        attributes:
        - parameter: audio.content
          sample_argument_name: local_file_path
          read_file: true
          description: Path to local audio file, e.g. /path/audio.wav
        - parameter: config.enable_automatic_punctuation
          description: 'When enabled, trascription results may include punctuation
            (available for select languages).

'
        - parameter: config.language_code
          description: |
            The language of the supplied audio. Even though additional languages are
            provided by alternative_language_codes, a primary language is still required.
      on_success:
      - loop:
          variable: result
          collection: "$resp.results"
          body:
          - comment:
            - First alternative is the most probable result
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
    - id: speech_transcribe_recognition_metadata_beta
      title: Adding recognition metadata (Local File) (Beta)
      description: "Adds additional details short audio file included in this recognition
        request \n"
      parameters:
        defaults:
        - audio.content = "resources/commercial_mono.wav"
        - config.metadata.interaction_type = VOICE_SEARCH
        - config.metadata.recording_device_type = SMARTPHONE
        - config.metadata.recording_device_name = "Pixel 3"
        - config.language_code = "en-US"
        attributes:
        - parameter: audio.content
          sample_argument_name: local_file_path
          read_file: true
          description: Path to local audio file, e.g. /path/audio.wav
        - parameter: config.metadata.interaction_type
          description: 'The use case of the audio, e.g. PHONE_CALL, DISCUSSION, PRESENTATION,
            et al.

'
        - parameter: config.metadata.recording_device_type
          description: The kind of device used to capture the audio
        - parameter: config.metadata.recording_device_name
          description: |
            The device used to make the recording.
            Arbitrary string, e.g. 'Pixel XL', 'VoIP', 'Cardioid Microphone', or other value.
        - parameter: config.language_code
          description: |
            The language of the supplied audio. Even though additional languages are
            provided by alternative_language_codes, a primary language is still required.
      on_success:
      - loop:
          variable: result
          collection: "$resp.results"
          body:
          - comment:
            - First alternative is the most probable result
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
    - id: speech_quickstart_beta
      description: "Performs synchronous speech recognition on an audio file."
      parameters:
        defaults:
        - config.encoding=MP3
        - config.sample_rate_hertz=44100
        - config.language_code="en-US"
        - audio.uri="gs://cloud-samples-data/speech/brooklyn_bridge.mp3"
        attributes:
        - parameter: config.sample_rate_hertz
          sample_argument_name: sample_rate_hertz
          description: "Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid values are: 8000-48000."
        - parameter: config.language_code
          sample_argument_name: language_code
          description: The language of the supplied audio.
        - parameter: audio.uri
          sample_argument_name: uri_path
          description: Path to the audio file stored on GCS.
      on_success:
      - loop:
          collection: $resp.results
          variable: result
          body:
          - define: transcript=result.alternatives[0].transcript
          - print: ["Transcript: %s", transcript]
    - id: speech_adaptation_beta
      description: "Performs synchronous speech recognition with speech adaptation."
      parameters:
        defaults:
        - config.encoding=MP3
        - config.sample_rate_hertz=44100
        - config.language_code="en-US"
        - config.speech_contexts[0].phrases[0]="Brooklyn Bridge"
        - config.speech_contexts[0].boost=20
        - audio.uri="gs://cloud-samples-data/speech/brooklyn_bridge.mp3"
        attributes:
        - parameter: config.sample_rate_hertz
          sample_argument_name: sample_rate_hertz
          description: "Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid values are: 8000-48000."
        - parameter: config.language_code
          sample_argument_name: language_code
          description: The language of the supplied audio.
        - parameter: config.speech_contexts[0].phrases[0]
          sample_argument_name: phrase
          description: Phrase "hints" help Speech-to-Text API recognize the specified phrases from your audio data.
        - parameter: config.speech_contexts[0].boost
          sample_argument_name: boost
          description: Positive value will increase the probability that a specific phrase will be recognized over other similar sounding phrases.
        - parameter: audio.uri
          sample_argument_name: uri_path
          description: Path to the audio file stored on GCS.
      on_success:
      - loop:
          variable: result
          collection: "$resp.results"
          body:
          - comment:
            - First alternative is the most probable result
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
    - id: speech_contexts_classes_beta
      description: "Performs synchronous speech recognition with static context classes."
      parameters:
        defaults:
        - config.encoding=MP3
        - config.sample_rate_hertz=24000
        - config.language_code="en-US"
        - config.speech_contexts[0].phrases[0]="$TIME"
        - audio.uri="gs://cloud-samples-data/speech/time.mp3"
        attributes:
        - parameter: config.sample_rate_hertz
          sample_argument_name: sample_rate_hertz
          description: "Sample rate in Hertz of the audio data sent in all `RecognitionAudio` messages. Valid values are: 8000-48000."
        - parameter: config.language_code
          sample_argument_name: language_code
          description: The language of the supplied audio.
        - parameter: config.speech_contexts[0].phrases[0]
          sample_argument_name: phrase
          description: Phrase "hints" help Speech-to-Text API recognize the specified phrases from your audio data. In this sample we are using a static class phrase ($TIME). Classes represent groups of words that represent common concepts that occur in natural language. We recommend checking out the docs page for more info on static classes.
        - parameter: audio.uri
          sample_argument_name: uri_path
          description: Path to the audio file stored on GCS.
      on_success:
      - loop:
          variable: result
          collection: "$resp.results"
          body:
          - comment:
            - First alternative is the most probable result
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
  - name: LongRunningRecognize
    flattening:
      groups:
      - parameters:
        - config
        - audio
    required_fields:
    - config
    - audio
    sample_code_init_fields:
    - config.encoding=FLAC
    - config.sample_rate_hertz=44100
    - config.language_code="en-US"
    - audio.uri=gs://bucket_name/file_name.flac
    retry_codes_name: non_idempotent
    retry_params_name: default
    timeout_millis: 60000
    long_running:
      return_type: google.cloud.speech.v1p1beta1.LongRunningRecognizeResponse
      metadata_type: google.cloud.speech.v1p1beta1.LongRunningRecognizeMetadata
      initial_poll_delay_millis: 20000
      poll_delay_multiplier: 1.5
      max_poll_delay_millis: 45000
      total_poll_timeout_millis: 86400000
    samples:
      standalone:
      - region_tag: speech_transcribe_diarization_beta
        value_sets:
        - speech_transcribe_diarization_beta
    sample_value_sets:
    - id: speech_transcribe_diarization_beta
      title: Separating different speakers (Local File) (LRO) (Beta)
      description: |
        Print confidence level for individual words in a transcription of a short audio file
        Separating different speakers in an audio file recording
      parameters:
        defaults:
        - audio.content = "resources/commercial_mono.wav"
        - config.enable_speaker_diarization = True
        - config.diarization_speaker_count = 2
        - config.language_code = "en-US"
        attributes:
        - parameter: audio.content
          sample_argument_name: local_file_path
          read_file: true
          description: Path to local audio file, e.g. /path/audio.wav
        - parameter: config.enable_speaker_diarization
          description: |
            If enabled, each word in the first alternative of each result will be
            tagged with a speaker tag to identify the speaker.
        - parameter: config.diarization_speaker_count
          description: 'Optional. Specifies the estimated number of speakers in the
            conversation.

'
        - parameter: config.language_code
          description: The language of the supplied audio
      on_success:
      - loop:
          collection: "$resp.results"
          variable: result
          body:
          - comment:
            - First alternative has words tagged with speakers
          - define: alternative=result.alternatives[0]
          - print:
            - 'Transcript: %s'
            - alternative.transcript
          - comment:
            - Print the %s of each word
            - speaker_tag
          - loop:
              collection: alternative.words
              variable: word
              body:
              - print:
                - 'Word: %s'
                - word.word
              - print:
                - 'Speaker tag: %s'
                - word.speaker_tag
  - name: StreamingRecognize
    retry_codes_name: idempotent
    retry_params_name: default
    timeout_millis: 1000000
